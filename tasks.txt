- script to scrape github data to table
  - collaborated on a pr
  - pr merged (points derived from gh project board)
  - push events instead of commits --- optimize commit created to instead be tracking push events directly instead. (Pushed 3 commits to branch... instead of 3 separate commit created activities, points would be derived from number of commits pushed)
  - exclude merge commits
  - incorrect timestamp in slack messages

- build pages
  - home
  - people
  - leaderboard
  - projects
  - releases
  - issues
  - feed

- aggregate metrics
- badges, eod streak
- profile filter should also be applied for activity breakdown
- currently working on and stale prs...
- eod_missed as an activity (only applicable for core,intern)

- setup footer
- sitemap generation
- open graph metadata for pages

- script to migrate old leaderboard eod data to new one
- github scraper: exclude repos[] as env
- script to migrate old profile data to new one
    - update config.yaml to support social_profiles to store svg_urls (also update tests and schema.json)
    - table: add col. social_profile (JSON), joining_date (DATE), title (VARCHAR), bio (TEXT)
    - script to migrate from old leaderboard format to new one.

    {
      slack_user_id: U89999,
      profile_url: https://nikhila-c.com
      social_medias: {
        github: git/rithviknishad
        portfolio: https://rithviknishad.dve
        tree-nation: https://lskfjdlfkgj.com
      }
    }


- scraper db ingest, and dump scripts
- update scraper to respect X-Poll-Interval
- setup pre-commit hooks and prettier configs
- script to update github username of old user, or auto do it by: traverse all contributors, find all contributors with duplicate github_pk_id, and merge them into single one
- setup sentry error reporting for scraper



## Aggregates

aggregate_definition:
  slug:              pr_turn_around_time                          primary key
  name:              PR Avg. turn-around time                     varchar
  desc:              The average duration between the P           text
  value_type:        duration                                     enum(duration | number)

contributor_aggregate:
  - definition:        pr_turn_around_time
    contributor:       NikhilA8606
    value:             Duration(2d 14h)

  - definition:        pr_turn_around_time
    contributor:       rithviknishad
    value:             Duration(2d 14h)

## Badges

badge_definition:
  slug:              eod_streak
  name:              EOD Streak Badge
  desc:              Earn this badge by consistently posting every day for 5 days
  variants:          {
                       "1x": { desc: "", svg_url: "https://.../bronze.svg" }
                       "2x": { desc: "", svg_url: "https://.../silver.svg" }
                       "3x": { desc: "", svg_url: "https://.../gold.svg" }
                     }

contributor_badge:
  - slug:              eod_streak__NikhilA8606__1x
    badge:             eod_streak
    contributor:       NikhilA8606
    variant:           1x
    achieved_on:       2025-11-10

  - slug:              eod_streak__NikhilA8606__2x
    badge:             eod_streak
    contributor:       NikhilA8606
    variant:           2x
    achieved_on:       2025-11-12

  - slug:              something__rithviknishad__default
    badge:             eod_streak
    contributor:       rithviknishad
    variant:           default
    achieved_on:       2025-11-12

scraper run workflow

before this, main leaderboard's db-import should be called to create tables and import contributors

 - pnpm run import --db="../db-data"
 - pnpm run scrape --db="../db-data"
 - pnpm run export --db="../db-data"

after this, main leaderboard's db-export should be called to dump leaderboard managed datas such as contributors